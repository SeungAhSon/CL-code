{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## USING THE YELP DATASET ##\n",
      "## LOADING ACTIVATION VECTORS ##\n"
     ]
    }
   ],
   "source": [
    "ROC_IMAGE_PATH = \"images\"\n",
    "Path(ROC_IMAGE_PATH).mkdir(parents=True, exist_ok=True)  # for the ROC images\n",
    "\n",
    "DATASET = \"yelp\"\n",
    "print(\"## USING THE YELP DATASET ##\")\n",
    "\n",
    "# decision which vector type should be loaded\n",
    "# VECTOR_TYPE = \"training_based\"\n",
    "VECTOR_TYPE = \"activations\"\n",
    "\n",
    "# For a fair comparison of the ROC curves between the activation and the steering vectors we need to only use the activation vectors, where we have found steering vectors\n",
    "# COMPARISON_TYPE = \"fair\"\n",
    "COMPARISON_TYPE = \"all\"  # use all activation vectors\n",
    "\n",
    "ACTIVATIONS_VECTOR_PATH = os.getenv(\"ACTIVATIONS_PATH_YELP\")\n",
    "ACTIVATIONS_VECTOR_FILES = glob.glob(\n",
    "    f\"{ACTIVATIONS_VECTOR_PATH}/{DATASET}*\"\n",
    ") + glob.glob(\n",
    "    f\"{ACTIVATIONS_VECTOR_PATH}/{DATASET.title()}*\"\n",
    ")  # .title() because we saved the yelp files as Yelp...\n",
    "\n",
    "TRAINED_STEERING_VECTOR_PATH = os.getenv(\"TRAINED_VECTORS_PATH_Yelp\")\n",
    "TRAINED_STEERING_VECTOR_FILES = glob.glob(f\"{TRAINED_STEERING_VECTOR_PATH}/*\")\n",
    "TRAINED_STEERING_VEC_MIN_LOSS = 5\n",
    "\n",
    "if VECTOR_TYPE == \"training_based\":\n",
    "    print(\"## LOADING STEERING VECTORS ##\")\n",
    "elif VECTOR_TYPE == \"activations\":\n",
    "    print(\"## LOADING ACTIVATION VECTORS ##\")\n",
    "else:\n",
    "    print(\"Options for VECTOR_TYPE are -training_based- or -activations-\")\n",
    "    exit(-1)\n",
    "\n",
    "df_yelp = pd.read_pickle(\"../datasets/pkl/yelp.pkl\")\n",
    "\n",
    "positive, positive_acti = [], []\n",
    "negative, negative_acti = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading trained steering vecs: 0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# if VECTOR_TYPE == \"training_based\":\n",
    "# always load the steering vectors. We need them for a fair comparison with the activations\n",
    "for file in tqdm(TRAINED_STEERING_VECTOR_FILES, desc=\"Loading trained steering vecs\"):\n",
    "    with open(file, \"rb\") as f:\n",
    "        a = pickle.load(f)\n",
    "        for key, value in a.items():\n",
    "            target_sentence = key\n",
    "            steering_vector = value[0]\n",
    "            for vec_i, vec in enumerate(\n",
    "                steering_vector\n",
    "            ):  # the vectors were saved as tensors with device=cuda. shape is 1,4096 and therefore squeeze\n",
    "                steering_vector[vec_i] = (\n",
    "                    steering_vector[vec_i].detach().cpu().numpy().squeeze()\n",
    "                )\n",
    "            activations = value[1]\n",
    "            loss = value[2].detach().cpu().numpy().item()\n",
    "            epoch = value[3]\n",
    "            gen_text = value[4]\n",
    "            label = value[5]\n",
    "\n",
    "            if loss < TRAINED_STEERING_VEC_MIN_LOSS:\n",
    "                if label:\n",
    "                    positive.append([steering_vector, target_sentence, loss, label])\n",
    "                else:\n",
    "                    negative.append([steering_vector, target_sentence, loss, label])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive trained steering samples with loss < 5: 0\n",
      "Number of negative trained steering samples with loss < 5: 0\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Number of positive trained steering samples with loss < {TRAINED_STEERING_VEC_MIN_LOSS}: {len(positive)}\"\n",
    ")\n",
    "print(\n",
    "    f\"Number of negative trained steering samples with loss < {TRAINED_STEERING_VEC_MIN_LOSS}: {len(negative)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading activations: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m     negative \u001b[38;5;241m=\u001b[39m negative_acti\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m COMPARISON_TYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 37\u001b[0m     positive \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositive_acti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     negative \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(negative_acti, \u001b[38;5;241m10000\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of activation-based positive samples: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(positive)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm2vec/lib/python3.10/random.py:482\u001b[0m, in \u001b[0;36mRandom.sample\u001b[0;34m(self, population, k, counts)\u001b[0m\n\u001b[1;32m    480\u001b[0m randbelow \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_randbelow\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m k \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n:\n\u001b[0;32m--> 482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample larger than population or is negative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    483\u001b[0m result \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m k\n\u001b[1;32m    484\u001b[0m setsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m21\u001b[39m        \u001b[38;5;66;03m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "if VECTOR_TYPE == \"activations\":\n",
    "    positive = np.asarray(positive, dtype=\"object\")\n",
    "    negative = np.asarray(negative, dtype=\"object\")\n",
    "    idx = 0\n",
    "    for file in tqdm(ACTIVATIONS_VECTOR_FILES, desc=\"Loading activations\"):\n",
    "        if (idx == 4) and (\n",
    "            COMPARISON_TYPE == \"all\"\n",
    "        ):  # we can't load all activations vectors due to memory constraints\n",
    "            break\n",
    "        with open(file, \"rb\") as f:\n",
    "            a = pickle.load(f)\n",
    "            for entry in a:\n",
    "                df_entry = df_yelp.loc[entry[0]]\n",
    "                label = df_entry[\"sentiment\"]\n",
    "                target_sentence = entry[1]\n",
    "                activation_vectors = entry[\n",
    "                    2\n",
    "                ]  # list of 33 vectors. Each vector has 4096 values\n",
    "\n",
    "                if COMPARISON_TYPE == \"fair\":\n",
    "                    steering_vec_exists = (target_sentence in positive[:, 1]) or (\n",
    "                        target_sentence in negative[:, 1]\n",
    "                    )\n",
    "                    if not steering_vec_exists:\n",
    "                        continue\n",
    "\n",
    "                if label:\n",
    "                    positive_acti.append([activation_vectors, target_sentence, label])\n",
    "                else:\n",
    "                    negative_acti.append([activation_vectors, target_sentence, label])\n",
    "        idx += 1\n",
    "\n",
    "    if COMPARISON_TYPE == \"fair\":\n",
    "        positive = positive_acti\n",
    "        negative = negative_acti\n",
    "    if COMPARISON_TYPE == \"all\":\n",
    "        positive = random.sample(positive_acti, 10000)\n",
    "        negative = random.sample(negative_acti, 10000)\n",
    "\n",
    "    print(f\"Number of activation-based positive samples: {len(positive)}\")\n",
    "    print(f\"Number of activation-based negative samples: {len(negative)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.5\n",
    "training_set_size = int(split_ratio * len(positive))\n",
    "train_positive = positive[:training_set_size]\n",
    "test_positive = positive[training_set_size:]\n",
    "\n",
    "training_set_size = int(split_ratio * len(negative))\n",
    "train_negative = negative[:training_set_size]\n",
    "test_negative = negative[training_set_size:]\n",
    "\n",
    "X, y = [], []\n",
    "fpr_list, tpr_list, roc_auc_list = [], [], []\n",
    "\n",
    "if VECTOR_TYPE == \"training_based\":\n",
    "    # chosen_indices = [0,1,2] # commented for tests\n",
    "    # description_indices = [18,19,20] # commented for tests\n",
    "    chosen_indices = [0]\n",
    "    description_indices = [18]\n",
    "elif COMPARISON_TYPE == \"fair\":\n",
    "    # chosen_indices = [18,19,20] # commented for tests\n",
    "    # description_indices = [18,19,20] # commented for tests\n",
    "    chosen_indices = [18]\n",
    "    description_indices = [18]\n",
    "elif VECTOR_TYPE == \"activations\":\n",
    "    # we only want to plot chosen layers, so that the plot isn't cluttered\n",
    "    all_indices = range(33)\n",
    "    # chosen_indices = [0,1,2,3,5,10,15,18,19,20,25,30] # commented for tests\n",
    "    chosen_indices = [15, 16]\n",
    "    description_indices = chosen_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/load the classifier for the vectors\n",
    "for i in tqdm(chosen_indices, desc=\"Calculating ROC per chosen layer\"):\n",
    "\n",
    "    for n in train_positive:\n",
    "        X.append(n[0][i])\n",
    "        y.append(1)\n",
    "    for n in train_negative:\n",
    "        X.append(n[0][i])\n",
    "        y.append(0)\n",
    "\n",
    "    clf = LogisticRegression(random_state=0, max_iter=1000).fit(X, y)\n",
    "\n",
    "    Ts = 0\n",
    "    Fs = 0\n",
    "    preds = []\n",
    "    test_y = []\n",
    "\n",
    "    for n in test_positive:\n",
    "        pred = clf.predict_proba([n[0][i]])[0]\n",
    "        cls = np.argmax(pred)\n",
    "        if cls:\n",
    "            Ts += 1\n",
    "        else:\n",
    "            Fs += 1\n",
    "        preds.append(pred)\n",
    "        test_y.append(1)\n",
    "\n",
    "    for n in test_negative:\n",
    "        pred = clf.predict_proba([n[0][i]])[0]\n",
    "        cls = np.argmax(pred)\n",
    "        if not cls:\n",
    "            Ts += 1\n",
    "        else:\n",
    "            Fs += 1\n",
    "        preds.append(pred)\n",
    "        test_y.append(0)\n",
    "\n",
    "    # print(clf.score(test_y))\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(test_y, [p[1] for p in preds])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    fpr_list.append(fpr)\n",
    "    tpr_list.append(tpr)\n",
    "    roc_auc_list.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "towards_red_cmap = plt.cm.get_cmap(\"YlOrRd\")  # choose colormap\n",
    "if (VECTOR_TYPE == \"training_based\") or (COMPARISON_TYPE == \"fair\"):\n",
    "    min_cmap_value = 0.89  # except for one value, the values presented in the figure are above 0.9. Therefore we want to scale the colormap accordingly\n",
    "elif VECTOR_TYPE == \"activations\":\n",
    "    min_cmap_value = 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get an expressive color at the top range of values we utilize exponential scaling\n",
    "color_value_rescaled_list = [\n",
    "    np.exp(\n",
    "        (\n",
    "            (roc_auc - min_cmap_value) / (1.0 - min_cmap_value) * 1.0\n",
    "            if roc_auc > min_cmap_value\n",
    "            else 0.2\n",
    "        )\n",
    "    )\n",
    "    - 1\n",
    "    for roc_auc in roc_auc_list\n",
    "]\n",
    "max_color_value_rescaled = np.max(color_value_rescaled_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "for i, _ in tqdm(enumerate(fpr_list), desc=\"Plotting ROC curves\"):\n",
    "    roc_auc = roc_auc_list[i]\n",
    "\n",
    "    # color values have to be between 0 and 1 for the cmap. Therefore, we scale it accordingly\n",
    "    color_value_rescaled = color_value_rescaled_list[i] / max_color_value_rescaled\n",
    "\n",
    "    title = (\n",
    "        f\"Receiver Operating Characteristic - Yelp / {VECTOR_TYPE}\"\n",
    "        if (VECTOR_TYPE == \"training_based\")\n",
    "        else f\"Receiver Operating Characteristic - Yelp / {VECTOR_TYPE} / {COMPARISON_TYPE}\"\n",
    "    )\n",
    "    # plt.title(title)\n",
    "    plt.axis(\"square\")\n",
    "    plt.plot(\n",
    "        fpr_list[i],\n",
    "        tpr_list[i],\n",
    "        label=f\"Layer {description_indices[i]} / AUC={roc_auc:.2f}\",\n",
    "        color=towards_red_cmap(color_value_rescaled),\n",
    "    )\n",
    "    plt.legend(loc=\"lower right\", fontsize=13)\n",
    "    plt.grid(color=\"lightgray\", linestyle=\"-\", linewidth=1)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    # plt.xlim([0, 1])\n",
    "    # plt.ylim([0, 1])\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize=15)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize=15)\n",
    "    img_name = (\n",
    "        f\"ROC_yelp_{VECTOR_TYPE}.pdf\"\n",
    "        if (VECTOR_TYPE == \"training_based\")\n",
    "        else f\"ROC_yelp_{VECTOR_TYPE}_{COMPARISON_TYPE}.pdf\"\n",
    "    )\n",
    "    plt.savefig(f\"{ROC_IMAGE_PATH}/{img_name}\", format=\"pdf\")\n",
    "\n",
    "    # print(f\"Trainingdata Statistics: Positive Training Samples: {len(train_positive)} Negative Training Samples: {len(train_negative)}\")\n",
    "    # print(f\"Testdata Statsitics: Positive Test Samples: {len(test_positive)} Negative Test Samples: {len(test_negative)}\")\n",
    "    # print(f\"Number of correct classified  sentences: {Ts}\")\n",
    "    # print(f\"Number of incorrect classified  sentences: {Fs}\")\n",
    "    # print(f\"Percentage of correct classifications: {Ts / (Ts+Fs)}\\n\")\n",
    "    #####################################e################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
