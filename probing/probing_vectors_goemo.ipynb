{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/DLR-SC/style-vectors-for-steering-llms/blob/main/scripts/probing_study/probing_study_goemo.py\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"]=\"4\" # 멀티 스레드로 시스템 과부화 막기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import utils.dataset_loader as dsl\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from utils.steering_vector_loader import load_activations_goemo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROC_IMAGE_PATH = \"./images\"\n",
    "DATASET=\"GoEmo\"\n",
    "\n",
    "# \"training_based\", \"activations\"\n",
    "VECTOR_TYPE = \"activations\"\n",
    "\n",
    "# For a fair comparison of the ROC curves between the activation and the steering vectors we need to only use the activation vectors, where we have found steering vectors\n",
    "COMPARISON_TYPE = \"all\"\n",
    "# COMPARISON_TYPE = \"fair\"\n",
    "\n",
    "ACTIVATION_VECTOR_PATH = os.getenv(\"ACTIVATIONS_PATH_GoEmo\")\n",
    "\n",
    "TRAINED_STEERING_VECTOR_PATH = os.getenv(\"TRAINED_VECTORS_PATH_GoEmo\")\n",
    "TRAINED_STEERING_VECTOR_FILES = glob.glob(f'{TRAINED_STEERING_VECTOR_PATH}/*')\n",
    "TRAINED_STEERING_VEC_MIN_LOSS = 5\n",
    "\n",
    "if VECTOR_TYPE == \"training_based\":\n",
    "    print(\"## LOADING TRAINED STEERING VECTORS ##\")\n",
    "elif VECTOR_TYPE == \"activations\":\n",
    "    if COMPARISON_TYPE==\"fair\":\n",
    "        print(\"## LOADING ACTIVATION VECTORS in the fair setting##\")\n",
    "    else:        \n",
    "        print(\"## LOADING ACTIVATION VECTORS ##\")\n",
    "else:\n",
    "    print(\"Options for VECTOR_TYPE are -training_based- or -activations-\")\n",
    "    exit(-1)\n",
    "\n",
    "### LOADING ACTIVATION VECTORS for train and test set\n",
    "go_emo_train, go_emo_test = load_activations_goemo(ACTIVATION_VECTOR_PATH)\n",
    "\n",
    "# we dont have activations for all entries\n",
    "go_emo_train = [entry for entry in go_emo_train if len(entry) == 3]\n",
    "go_emo_test = [entry for entry in go_emo_test if len(entry) == 3]\n",
    "\n",
    "go_emo_train_tmp = np.array(go_emo_train, dtype = object)\n",
    "go_emo_train_tmp_dic = list(go_emo_train_tmp[:,1])\n",
    "df_train_tmp = pd.DataFrame(go_emo_train_tmp_dic, columns =[\"text\", \"labels\", \"id\"])\n",
    "\n",
    "go_emo_test_tmp = np.array(go_emo_test, dtype = object)\n",
    "go_emo_test_tmp_dic = list(go_emo_test_tmp[:,1])\n",
    "df_test_tmp = pd.DataFrame(go_emo_test_tmp_dic, columns =[\"text\", \"labels\", \"id\"])\n",
    "\n",
    "### LOADING TRAINED STEERING VECTORS\n",
    "labels =  [25, 17, 14, 2, 26, 11]\n",
    "means = []\n",
    "total_mean = []\n",
    "\n",
    "df_goemo = dsl.load_goemo()\n",
    "go_emo_train_steering = []\n",
    "go_emo_test_steering = []\n",
    "\n",
    "go_emo_train_actis_fair = []\n",
    "go_emo_test_actis_fair = []\n",
    "\n",
    "for file in tqdm(TRAINED_STEERING_VECTOR_FILES, desc=\"Loading trained steering vecs\"):\n",
    "    with open(file, 'rb') as f:\n",
    "        a = pickle.load(f)\n",
    "        \n",
    "        for key, value in a.items():\n",
    "            target_sentence = key\n",
    "            steering_vector = value[0]\n",
    "            for vec_i, vec in enumerate(steering_vector): # the vectors were saved as tensors with device=cuda. shape is 1,4096 and therefore squeeze\n",
    "                steering_vector[vec_i] = steering_vector[vec_i].detach().cpu().numpy().squeeze()\n",
    "            # activations = value[1]\n",
    "            loss = value[2].detach().cpu().numpy().item()\n",
    "            epoch = value[3]\n",
    "            # gen_text = value[4]\n",
    "            label = value[5]\n",
    "            \n",
    "            dsl_entry = df_goemo[df_goemo[\"text\"] == target_sentence]\n",
    "            \n",
    "\n",
    "            if loss < TRAINED_STEERING_VEC_MIN_LOSS:\n",
    "\n",
    "                if not (df_train_tmp[df_train_tmp[\"text\"] == target_sentence]).empty:  \n",
    "                    found = df_train_tmp[df_train_tmp[\"text\"] == target_sentence]           \n",
    "                    go_emo_train_actis_fair.append(go_emo_train[found.index[0]])   \n",
    "                    go_emo_train_steering.append([label.item(), dsl_entry.to_dict(orient=\"list\"), steering_vector, loss]) \n",
    "\n",
    "                elif not (df_test_tmp[df_test_tmp[\"text\"] == target_sentence]).empty: \n",
    "                    found = df_test_tmp[df_test_tmp[\"text\"] == target_sentence]           \n",
    "                    go_emo_test_actis_fair.append(go_emo_test[found.index[0]])   \n",
    "                    go_emo_test_steering.append([label.item(), dsl_entry.to_dict(orient=\"list\"), steering_vector, loss])     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_classification(y_train,y_test,y_score, n_classes, target_names, layer_indices):\n",
    "    from itertools import cycle\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "    label_binarizer = LabelBinarizer().fit(y_train)\n",
    "    y_onehot_test = label_binarizer.transform(y_test)\n",
    "    y_onehot_test.shape  # (n_samples, n_classes)\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "\n",
    "    # store the fpr, tpr, and roc_auc for all averaging strategies\n",
    "    fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_onehot_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    print(f\"Micro-averaged One-vs-Rest ROC AUC score:\\n{roc_auc['micro']:.2f}\")\n",
    "\n",
    "    plt.plot(\n",
    "        fpr[\"micro\"],\n",
    "        tpr[\"micro\"],\n",
    "        #label=f\"micro-average ROC curve (AUC = {roc_auc['micro']:.2f})\",\n",
    "        label=f\"micro-average (AUC = {roc_auc['micro']:.2f})\",\n",
    "        color=\"deeppink\",\n",
    "        linestyle=\":\",\n",
    "        linewidth=4,\n",
    "    )\n",
    "\n",
    "    colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\", \"red\", \"purple\", \"green\"])\n",
    "    for class_id, color in zip(range(n_classes), colors):\n",
    "        RocCurveDisplay.from_predictions(\n",
    "            y_onehot_test[:, class_id],\n",
    "            y_score[:, class_id],\n",
    "            #name=f\"ROC curve for {target_names[class_id]}\",\n",
    "            name=f\"{target_names[class_id]}\",\n",
    "            color=color,\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\") #, label=\"ROC curve for chance level (AUC = 0.5)\")\n",
    "    plt.axis(\"square\")\n",
    "    plt.grid(color='lightgray', linestyle='-', linewidth=1)\n",
    "    plt.xlabel(\"False Positive Rate\", fontsize = 15)\n",
    "    plt.ylabel(\"True Positive Rate\", fontsize = 15)\n",
    "    plt.legend(loc = \"lower right\", fontsize = 13)\n",
    "    fig_name_indices = \"\"\n",
    "    for layer_idx in layer_indices:\n",
    "        fig_name_indices += f\"{layer_idx}_\"\n",
    "    fig_name = f\"ROC_goemo_{fig_name_indices}steering.pdf\" if VECTOR_TYPE == \"training_based\" else f\"ROC_goemo_{fig_name_indices}actis_{COMPARISON_TYPE}.pdf\"\n",
    "    plt.savefig(f\"{ROC_IMAGE_PATH}/{fig_name}\")\n",
    "    plt.clf()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression iterating over all layers\n",
    "def single_layer_classification(layer_index):\n",
    "    #한 레이어만 input으로 받아서 logistic regression classifier 학습\n",
    "    \n",
    "    if (VECTOR_TYPE == \"activations\") and (COMPARISON_TYPE == \"all\"):\n",
    "        Y_train = []\n",
    "        X_train = []\n",
    "        for entry in go_emo_train:\n",
    "            Y_train.append(labels.index(entry[1]['labels'][0]))\n",
    "            X_train.append(entry[2][layer_index])\n",
    "\n",
    "        Y_test = []\n",
    "        X_test = []\n",
    "        for entry in go_emo_test:\n",
    "            Y_test.append(labels.index(entry[1]['labels'][0]))\n",
    "            X_test.append(entry[2][layer_index])\n",
    "\n",
    "    else:\n",
    "        Y_25, Y_17, Y_14, Y_2, Y_26, Y_11 = [],[],[],[],[],[]\n",
    "        X_25, X_17, X_14, X_2, X_26, X_11 = [],[],[],[],[],[]\n",
    "        \n",
    "        entry_list = go_emo_train_steering if VECTOR_TYPE == \"training_based\" else go_emo_train_actis_fair\n",
    "\n",
    "        for entry in entry_list:\n",
    "            class_label = entry[1]['labels'][0]\n",
    "\n",
    "            if class_label == 25:\n",
    "                Y_25.append(labels.index(entry[1]['labels'][0]))\n",
    "                X_25.append(entry[2][layer_index-18])\n",
    "            elif class_label == 17:\n",
    "                Y_17.append(labels.index(entry[1]['labels'][0]))\n",
    "                X_17.append(entry[2][layer_index-18])\n",
    "            elif class_label == 14:\n",
    "                Y_14.append(labels.index(entry[1]['labels'][0]))\n",
    "                X_14.append(entry[2][layer_index-18])\n",
    "            elif class_label == 2:\n",
    "                Y_2.append(labels.index(entry[1]['labels'][0]))\n",
    "                X_2.append(entry[2][layer_index-18])\n",
    "            elif class_label == 26:\n",
    "                Y_26.append(labels.index(entry[1]['labels'][0]))\n",
    "                X_26.append(entry[2][layer_index-18])\n",
    "            elif class_label == 11:\n",
    "                Y_11.append(labels.index(entry[1]['labels'][0]))\n",
    "                X_11.append(entry[2][layer_index-18])\n",
    "            else:\n",
    "                print(f\"Didn't find {class_label}\")\n",
    "\n",
    "        X_train, X_test = [],[]\n",
    "        Y_train, Y_test = [], []\n",
    "        split_ratio = .5\n",
    "        for tup in [(X_25,Y_25), (X_17,Y_17), (X_14,Y_14), (X_2,Y_2), (X_26,Y_26), (X_11,Y_11)]:\n",
    "            end_train_idx = int(split_ratio * len(tup[0]))+1\n",
    "            X_train.extend(tup[0][0:end_train_idx])\n",
    "            Y_train.extend(tup[1][0:end_train_idx])\n",
    "            X_test.extend(tup[0][end_train_idx:-1])\n",
    "            Y_test.extend(tup[1][end_train_idx:-1])\n",
    "                \n",
    "\n",
    "    clf = LogisticRegression(multi_class='multinomial', max_iter = 20000, class_weight='balanced').fit(X_train, Y_train)\n",
    "    print(f\"Layer {layer_index} classification score: {clf.score(X_test,Y_test)}\")\n",
    "    plot_classification(Y_train,Y_test, clf.predict_proba(X_test), 6, [\"sadness\", \"joy\", \"fear\", \"anger\", \"surprise\", \"disgust\"], [layer_index])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression with concatenated layers, sliding window\n",
    "def multi_layer_classification(num_layers = 3, specific_layers = None):\n",
    "    \"\"\"Training a logistic regression classifier with multiple layers as input. \n",
    "    Currently it only works for the activation-based vectors.\n",
    "\n",
    "    :param int num_layers: How many layers per classifier, defaults to 3\n",
    "    :param array specific_layers: Which layers should be used , defaults to None\n",
    "    \"\"\"\n",
    "    \n",
    "    layer_indices_list = []\n",
    "    if specific_layers is not None:\n",
    "        layer_indices_list = [specific_layers] \n",
    "    else:\n",
    "        for i in range(0,33):\n",
    "            layer_indices_list.append(np.arange(i,i+num_layers))\n",
    "\n",
    "    \n",
    "    for layer_indices in layer_indices_list:\n",
    "\n",
    "        Y_train = []\n",
    "        X_train = []\n",
    "        for entry in go_emo_train:\n",
    "            Y_train.append(labels.index(entry[1]['labels'][0]))\n",
    "            entries = []\n",
    "            for layer_index in layer_indices:\n",
    "                entries.append(entry[2][layer_index])\n",
    "            X_train.append(np.concatenate(entries))\n",
    "\n",
    "        Y_test = []\n",
    "        X_test = []\n",
    "        for entry in go_emo_test:\n",
    "            Y_test.append(labels.index(entry[1]['labels'][0]))\n",
    "            entries = []\n",
    "            for layer_index in layer_indices:\n",
    "                entries.append(entry[2][layer_index])\n",
    "            X_test.append(np.concatenate(entries))\n",
    "\n",
    "        clf = LogisticRegression(multi_class='multinomial', max_iter = 10000, class_weight='balanced').fit(X_train, Y_train)\n",
    "        print(f\"Layer {layer_indices[0]} classification score: {clf.score(X_test,Y_test)}\")\n",
    "        plot_classification(Y_train,Y_test, clf.predict_proba(X_test), 6, [\"sadness\", \"joy\", \"fear\", \"anger\", \"surprise\", \"disgust\"], layer_indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers = [18,19,20] # commented for tests\n",
    "layers = [18]\n",
    "for layer in layers:\n",
    "    single_layer_classification(layer)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
