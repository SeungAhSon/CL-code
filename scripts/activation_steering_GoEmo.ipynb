{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0a9bd3d79044ebab37e3493f64b3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5504, bias=False)\n",
       "          (down_proj): Linear(in_features=5504, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "\n",
    "MODEL_PATH = '../model/sheared_llama_1.3B/'\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(MODEL_PATH).to(DEVICE)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function extracts the activation vectors for every layer during the forward pass of a prompt and saves them as .pkl files\n",
    "def process_dataset(dataset_name):\n",
    "    df = []\n",
    "    print(f\"Saving activations for {dataset_name} dataset!\")\n",
    "    if \"GoEmo\" in dataset_name:\n",
    "        df = pd.read_pickle('../datasets/pkl/go_emotions.pkl')\n",
    "    elif \"yelp\" in dataset_name:\n",
    "        df = pd.read_pickle('../datasets/pkl/yelp.pkl')\n",
    "        \n",
    "    actis, actis_train, actis_test = [],[],[]\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for index, row in tqdm(df.iterrows(), desc=f\"Iterating through all samples from the {DATASET} dataset and extracting the activations\", total=df.shape[0]):\n",
    "\n",
    "        # removing newlines from samples.\n",
    "        sentence = []\n",
    "        if \"GoEmo\" in dataset_name:\n",
    "            sentence = row['text'].replace('\\n', '')\n",
    "        else:\n",
    "            sentence = row['sample'].replace('\\n', '')\n",
    "        input_tokens = tokenizer(sentence, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "        # skip samples with more than 300 tokens, otherwise GPU runs out of memory\n",
    "        if len(input_tokens.input_ids) > 300: \n",
    "            continue\n",
    "        gen_text = model.forward(input_tokens.input_ids, output_hidden_states=True, return_dict=True)\n",
    "        hidden_states = []\n",
    "\n",
    "        #iterating over all layers and storing activations of the last token\n",
    "        for layer in gen_text['hidden_states']:\n",
    "            hidden_states.append(layer[0][-1].detach().cpu().numpy())\n",
    "\n",
    "        if DATASET == \"GoEmo\":\n",
    "            actis.append([index,row,hidden_states])\n",
    "        else:\n",
    "            # yelp store the labels in column 'sentiment', go emotion stores labels in 'labels' column.\n",
    "            actis.append([index, sentence, hidden_states, row['sentiment']])\n",
    "\n",
    "            i += 1\n",
    "            # save activations in batches\n",
    "            if i == 10000:\n",
    "                i = 0\n",
    "                with open(f'{PATH_TO_ACTIVATION_STORAGE}/{dataset_name}_activations_{j}.pkl', 'wb') as f:\n",
    "                    pickle.dump(actis, f)\n",
    "                del actis\n",
    "                del hidden_states\n",
    "                actis = []\n",
    "                j += 1\n",
    "    \n",
    "    if DATASET==\"GoEmo\":\n",
    "        actis_train = actis[0:4343] # training set\n",
    "        actis_test = actis[4343:4343+554] # test set\n",
    "        # we ignore the val set\n",
    "        with open(f'{PATH_TO_ACTIVATION_STORAGE}/{dataset_name}_activations_train.pkl', 'wb') as f:\n",
    "                pickle.dump(actis_train, f)\n",
    "        with open(f'{PATH_TO_ACTIVATION_STORAGE}/{dataset_name}_activations_test.pkl', 'wb') as f:\n",
    "                pickle.dump(actis_test, f)\n",
    "    else:    \n",
    "        # in case the number of samples is not dividable by 10000, we safe the rest\n",
    "        with open(f'{PATH_TO_ACTIVATION_STORAGE}/{dataset_name}_activations_{j}.pkl', 'wb') as f:\n",
    "                pickle.dump(actis, f)\n",
    "    \n",
    "    del actis\n",
    "    del hidden_states\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activations for GoEmo dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating through all samples from the GoEmo dataset and extracting the activations: 100%|██████████| 5410/5410 [02:45<00:00, 32.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# DATASET = \"yelp\", \"GoEmo\"\n",
    "DATASET = \"GoEmo\"\n",
    "\n",
    "PATH_TO_ACTIVATION_STORAGE=\"\"\n",
    "if DATASET==\"yelp\":     PATH_TO_ACTIVATION_STORAGE = \"../store_activation/yelp\"\n",
    "elif DATASET==\"GoEmo\":  PATH_TO_ACTIVATION_STORAGE = \"../store_activation/GoEmo\"\n",
    "\n",
    "process_dataset(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving activations for GoEmo dataset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating through all samples from the GoEmo dataset and extracting the activations: 100%|██████████| 5410/5410 [02:43<00:00, 33.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# DATASET = \"yelp\", \"GoEmo\"\n",
    "DATASET = \"GoEmo\"\n",
    "\n",
    "PATH_TO_ACTIVATION_STORAGE=\"\"\n",
    "if DATASET==\"yelp\":     PATH_TO_ACTIVATION_STORAGE = \"../store_activation/yelp\"\n",
    "elif DATASET==\"GoEmo\":  PATH_TO_ACTIVATION_STORAGE = \"../store_activation/GoEmo\"\n",
    "\n",
    "process_dataset(DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
